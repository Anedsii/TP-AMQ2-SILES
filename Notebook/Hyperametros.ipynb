{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Loading data from: ../data/\n",
      "INFO:__main__:Preprocessing data: Item_MRP\n",
      "INFO:__main__:Data prepared for training: X\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "AUTHORS: ANGELA EDITH SILES\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Imports\n",
    "import logging\n",
    "import os\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import xgboost as xgboost_regressor\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def preprocess_dataframe(pandas_df: pd.DataFrame):\n",
    "    \"\"\"Preprocess the dataframe obtained after applying feature engineering.\n",
    "    \n",
    "    Args:\n",
    "        pandas_df (pd.DataFrame): DataFrame obtained after loading.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Preprocessed DataFrame.\n",
    "    \"\"\"\n",
    "    logger.info('Preprocessing data: Item_MRP')\n",
    "    dataset = pandas_df.drop(columns=['Item_Identifier', 'Outlet_Identifier'])\n",
    "\n",
    "    # Split the dataset into train and test sets\n",
    "    df_train = dataset.loc[pandas_df['Set'] == 'train']\n",
    "    df_test = dataset.loc[pandas_df['Set'] == 'test']\n",
    "\n",
    "    return df_train, df_test\n",
    "\n",
    "class TuningHyperParametersPipeline(object):\n",
    "    \"\"\"Pipeline for tuning hyperparameters using Optuna and XGBoost.\"\"\"\n",
    "    \n",
    "    def __init__(self, input_path, output_path: str = None):\n",
    "        self.input_path = input_path\n",
    "        self.output_path = output_path\n",
    "\n",
    "    def load_data(self) -> pd.DataFrame:\n",
    "        \"\"\"Load the dataframe for processing.\n",
    "        \n",
    "        Returns:\n",
    "            pd.DataFrame: Loaded DataFrame.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            train_file = 'features.csv'\n",
    "            train_data = os.path.join(self.input_path, train_file)\n",
    "            pandas_df = pd.read_csv(train_data)\n",
    "            logger.info(\"Loading data from: %s\", self.input_path)\n",
    "        except (FileNotFoundError, PermissionError, OSError) as error_load_file:\n",
    "            logger.exception(\"An error occurred while loading data: %s\", error_load_file)\n",
    "\n",
    "        return pandas_df\n",
    "\n",
    "    def prepare_data_for_training(self, df: pd.DataFrame):\n",
    "        \"\"\"Prepare the data for training.\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): Dataframe to be trained.\n",
    "        \n",
    "        Returns:\n",
    "            x_train, y_train (pd.DataFrame, pd.Series): Datasets obtained after applying the machine learning model.\n",
    "        \"\"\"\n",
    "\n",
    "        global x_train\n",
    "        global y_train\n",
    "\n",
    "        df_train, df_test = preprocess_dataframe(pandas_df=df)\n",
    "\n",
    "        # Delete columns without data\n",
    "        df_train.drop(['Set'], axis=1, inplace=True)\n",
    "        df_test.drop(['Item_Outlet_Sales', 'Set'],\n",
    "                     axis=1, inplace=True)\n",
    "\n",
    "        seed = 28\n",
    "\n",
    "        # Split the dataset into training and validation sets\n",
    "        X = df_train.drop(columns='Item_Outlet_Sales')\n",
    "        logger.info('Data prepared for training: X')\n",
    "\n",
    "        y = df_train['Item_Outlet_Sales']\n",
    "\n",
    "        x_train, _, y_train, _ = train_test_split(\n",
    "            X, y, test_size=0.3, random_state=seed)\n",
    "        return x_train, y_train\n",
    "\n",
    "    def train_model(self, x_train, y_train):\n",
    "        \"\"\"Train the model and evaluate its performance.\n",
    "        \n",
    "        Args:\n",
    "            x_train (np.array): Features to be trained.\n",
    "            y_train (np.array): Target to be trained.\n",
    "        \"\"\"\n",
    "        seed = 28\n",
    "        model_trained = xgboost_regressor.XGBRegressor(\n",
    "            objective='reg:linear', n_estimators=10, random_state=seed)\n",
    "        try:\n",
    "            # Train the model\n",
    "            score_model = cross_val_score(\n",
    "                model_trained, x_train, y_train, scoring='neg_root_mean_squared_error', n_jobs=-1, cv=10)\n",
    "            logger.info('Model trained successfully')\n",
    "            logger.info('Score model: %s', score_model)\n",
    "            logger.info('Mean: %s, Std: %s', np.mean(score_model), np.std(score_model))\n",
    "            return score_model\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred while training the model: %s\", str(e))\n",
    "\n",
    "    def evaluate_score(self, param):\n",
    "        \"\"\"Return the score after applying xgboost regressor.\n",
    "        \n",
    "        Args:\n",
    "            param (_type_): Variable used as a parameter to pass to the XGB Regressor function.\n",
    "        \n",
    "        Returns:\n",
    "            float: Metric obtained after model training.\n",
    "        \"\"\"\n",
    "        model = xgboost_regressor.XGBRegressor(**param)\n",
    "        try:\n",
    "            root_mean_square_error = np.mean(cross_val_score(\n",
    "                model, x_train, y_train, cv=4, n_jobs=-1, scoring='neg_root_mean_squared_error'))\n",
    "            return root_mean_square_error\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred while returning the score: %s\", str(e))\n",
    "\n",
    "    def objective_function(self, trial):\n",
    "        \"\"\"Optuna objective function.\n",
    "        \n",
    "        Args:\n",
    "            trial (_type_): Description.\n",
    "        \"\"\"\n",
    "        # Define hyperparameters\n",
    "        param = {'sampling_method': 'gradient_based', 'reg_lambda':\n",
    "                 trial.suggest_uniform('lambda', 7.0, 17.0), 'reg_alpha': trial.suggest_uniform('alpha', 7.0, 17.0), 'learning_rate': trial.suggest_uniform('learning_rate', 0.05, 0.5),\n",
    "                 'colsample_bytree': trial.suggest_uniform('colsample_bytree', 0.4, 0.9),\n",
    "                 'n_estimators': trial.suggest_int('n_estimators', 0, 100)}\n",
    "        return self.evaluate_score(param)\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run the entire pipeline.\"\"\"\n",
    "        try:\n",
    "            data_frame = self.load_data()\n",
    "            x_trained, y_trained = self.prepare_data_for_training(data_frame)\n",
    "            model_trained = self.train_model(x_train=x_trained, y_train=y_trained)\n",
    "            study_object = optuna.create_study(\n",
    "                direction='minimize', sampler=TPESampler())\n",
    "            study_object.optimize(self.objective_function, n_trials=200)\n",
    "\n",
    "            fig = optuna.visualization.plot_parallel_coordinate(study_object)\n",
    "            fig.show()\n",
    "\n",
    "            logger.info('Best parameters: %s', study_object.best_params)\n",
    "        except Exception as e:\n",
    "            logger.exception(\"An error occurred in the pipeline: %s\", str(e))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        pipeline = TuningHyperParametersPipeline(\n",
    "            input_path='../data/',\n",
    "            output_path='')\n",
    "        pipeline.run()\n",
    "    except Exception as e:\n",
    "        logger.exception(\"An error occurred: %s\", str(e))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
